{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "453dace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 쿼리를 입력하세요.Hello my name is minho\n",
      "rank\tIndex\tscore\tsentence\n",
      "1\t551\t0.7142857142857143\tThey listened to him and did not ride on them.\n",
      "2\t251\t0.6923076923076923\tI am nine years old.\n",
      "3\t101\t0.6428571428571429\tThen he eats it all by himself.\n",
      "4\t173\t0.625\tSo English is used by many people.\n",
      "5\t350\t0.625\tGeorge helps his team win many games.\n",
      "6\t358\t0.625\tGeorge is the best baseball player on his team.\n",
      "7\t538\t0.625\tMy hobby is traveling.\n",
      "8\t596\t0.625\tIt shows how life will be fifty years from now.\n",
      "9\t282\t0.6\tThey were two nice cameras.\n",
      "10\t392\t0.6\tHighways were only for horses.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "def preprocess(sentence):\n",
    "    preprocessed_sentence = sentence.strip().split(\" \")\n",
    "    return preprocessed_sentence\n",
    "\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = []\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines()\n",
    "    for line in lines:\n",
    "        tokens = preprocess(line)\n",
    "        file_tokens_pairs.append(tokens)\n",
    "    return file_tokens_pairs\n",
    "\n",
    "#function that converts sentence to lowered sentence\n",
    "def lowering(sentence):\n",
    "    lowered_sentence = []\n",
    "    for i in range(len(sentence)):\n",
    "        lowered_sentence.append(sentence[i].lower())\n",
    "    return ''.join(lowered_sentence)\n",
    "\n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    lowered_preprocessed_query_set = set(lowering(preprocessed_query))\n",
    "    score_dict = {}\n",
    "    for i in range(len(preprocessed_sentences)):\n",
    "        lowered_preprocessed_sentence = lowering(preprocessed_sentences[i])\n",
    "        lowered_preprocessed_sentence_set = set(lowered_preprocessed_sentence)\n",
    "        all_tokens = lowered_preprocessed_query_set | lowered_preprocessed_sentence_set\n",
    "        same_tokens = lowered_preprocessed_query_set & lowered_preprocessed_sentence_set\n",
    "        similarity = len(same_tokens) / len(all_tokens)\n",
    "        score_dict[i] = similarity\n",
    "    return score_dict\n",
    "\n",
    "# 1. Indexing\n",
    "## https://github.com/jungyeul/korean-parallel-corpora\n",
    "file_name = \"jhe-koen-dev.en\"\n",
    "file_tokens_pairs = indexing(file_name)\n",
    "\n",
    "# 2. Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요.\")\n",
    "preprocessed_query = preprocess(query)\n",
    "\n",
    "# 3. Calculate similarities based on a same token set\n",
    "score_dict = calc_similarity(preprocessed_query, file_tokens_pairs)\n",
    "\n",
    "# 4. Sort the similarity list\n",
    "sorted_score_list = sorted(score_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 5. Print the result\n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")\n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep = \"\\t\")\n",
    "    rank = 1\n",
    "    for i, score  in sorted_score_list:\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep = \"\\t\")\n",
    "        if rank == 10:\n",
    "            break\n",
    "        rank = rank + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
